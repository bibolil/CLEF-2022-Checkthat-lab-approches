{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JjDgcvU2FBJX",
        "outputId": "4e9440eb-7092-49f9-cedb-2d215ba76465"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.18.0)\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.7/dist-packages (0.90)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.5.1)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.49)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.5)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.8)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from xgboost) (1.4.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers xgboost"
      ],
      "id": "JjDgcvU2FBJX"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "96f16ab0-b2cd-4582-b547-ed5892590e98",
        "outputId": "da5c8759-f0ce-4525-a460-cf05c1723b88"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.43.228.58:8470\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.43.228.58:8470\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n",
            "WARNING:absl:`tf.distribute.experimental.TPUStrategy` is deprecated, please use  the non experimental symbol `tf.distribute.TPUStrategy` instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, TFAutoModel, AutoConfig, pipeline, AutoModel\n",
        "import re\n",
        "import io\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from sklearn.metrics import f1_score, accuracy_score,precision_score,recall_score\n",
        "import os\n",
        "from google.colab import drive\n",
        "seed =45\n",
        "np.random.seed(seed)\n",
        "tf.random.set_seed(seed)\n",
        "tpu_strategy = tf.distribute.experimental.TPUStrategy(tf.distribute.cluster_resolver.TPUClusterResolver.connect())\n",
        "drive.mount('/gdrive')"
      ],
      "id": "96f16ab0-b2cd-4582-b547-ed5892590e98"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "624d06b1-2fce-4fe8-bc91-27e1794a36da"
      },
      "outputs": [],
      "source": [
        "model_type=\"UBC-NLP/ARBERT\"\n",
        "language=\"Ara\"\n",
        "data_dir=\"/content\"\n",
        "train_file=\"ara_train.csv\"\n",
        "dev_file=\"ara_dev.csv\"\n",
        "model_dir=\"/content\"\n",
        "model_file=f\"{language}-Mono-Model.h5\"\n",
        "train_path=os.path.join(data_dir,train_file)\n",
        "dev_path=os.path.join(data_dir,dev_file)\n",
        "model_path=os.path.join(model_dir,model_file)"
      ],
      "id": "624d06b1-2fce-4fe8-bc91-27e1794a36da"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "df405117-135d-493c-a926-bf5e1f1d2611"
      },
      "outputs": [],
      "source": [
        "train_data=pd.read_csv(train_path)\n",
        "valid_data=pd.read_csv(dev_path)"
      ],
      "id": "df405117-135d-493c-a926-bf5e1f1d2611"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "fU3oprQI4Lpb"
      },
      "outputs": [],
      "source": [
        "def balanced_batch(data):\n",
        "  harmful=data.loc[data[\"class_label\"]==1]\n",
        "  norm_count=int(len(harmful)*1.5)\n",
        "  normal=data.loc[data[\"class_label\"]==0].sample(n=norm_count)\n",
        "  data=harmful.append(normal).sample(frac=1).reset_index(drop=True)\n",
        "  return data\n",
        "\n",
        "train_data=balanced_batch(train_data)"
      ],
      "id": "fU3oprQI4Lpb"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "a8d70536-32a5-43ec-8c79-663367cf8b0e"
      },
      "outputs": [],
      "source": [
        "def gen_data(data,tokenizer_type=model_type):\n",
        "    data_dict={}\n",
        "    data_dict[\"harmful_label\"]=tf.convert_to_tensor(data[\"class_label\"].values.astype(int))\n",
        "    data_dict[\"text\"]=data[\"tweet_text\"].values.astype(\"str\")\n",
        "    tokenizer = AutoTokenizer.from_pretrained(tokenizer_type)\n",
        "    input_ids, input_masks = [],[]\n",
        "    for sentence in data_dict[\"text\"]:\n",
        "        inputs = tokenizer.encode_plus(sentence, add_special_tokens=True,max_length=326,truncation=True, padding='max_length',return_attention_mask=True, return_token_type_ids=True)\n",
        "        input_ids.append(inputs['input_ids'])\n",
        "        input_masks.append(inputs['attention_mask'])\n",
        "    data_dict[\"input_ids\"]=tf.convert_to_tensor(input_ids) \n",
        "    data_dict[\"input_masks\"]=tf.convert_to_tensor(input_masks)  \n",
        "    return data_dict\n",
        "\n",
        "train=gen_data(train_data)\n",
        "valid=gen_data(valid_data)"
      ],
      "id": "a8d70536-32a5-43ec-8c79-663367cf8b0e"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "z2bTSK_Qd7Rv"
      },
      "outputs": [],
      "source": [
        "# def create_mono_model(transformer):\n",
        "#     input_ids= tf.keras.layers.Input(shape=(326,), dtype='int32')\n",
        "#     input_masks = tf.keras.layers.Input(shape=(326,), dtype='int32')\n",
        "#     embedding_layer=transformer(input_ids, attention_mask=input_masks)[0]\n",
        "#     #embedding_layer= tf.keras.layers.SpatialDropout1D(0.2)(embedding_layer)\n",
        "    \n",
        "#     harmful=tf.keras.layers.Bidirectional(tf.keras.layers.GRU(64, return_sequences=True, dropout=0.2))(embedding_layer)\n",
        "#     harmful=tf.keras.layers.Bidirectional(tf.keras.layers.GRU(32, return_sequences=True, dropout=0.1))(harmful)\n",
        "#     harmful = tf.keras.layers.Conv1D(32, kernel_size = 3, padding = \"valid\", kernel_initializer = \"glorot_uniform\")(harmful)\n",
        "#     avg_pool_harmful = tf.keras.layers.GlobalAveragePooling1D()(harmful)\n",
        "#     max_pool_harmful = tf.keras.layers.GlobalMaxPooling1D()(harmful)\n",
        "#     harmful = tf.keras.layers.concatenate([avg_pool_harmful, max_pool_harmful])\n",
        "#     harmful = tf.keras.layers.Dropout(0.1)(harmful)\n",
        "#     output_harmful=tf.keras.layers.Dense(1, activation=\"sigmoid\",name=\"output_harmful\")(harmful)\n",
        "\n",
        "#     model = tf.keras.Model(inputs=[input_ids, input_masks], outputs =output_harmful)\n",
        "    \n",
        "#     return model"
      ],
      "id": "z2bTSK_Qd7Rv"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "da19818d-f3ba-401d-a79a-4fdcad857dc9"
      },
      "outputs": [],
      "source": [
        "def create_mono_model(transformer):\n",
        "    input_ids= tf.keras.layers.Input(shape=(326,), dtype='int32')\n",
        "    input_masks = tf.keras.layers.Input(shape=(326,), dtype='int32')\n",
        "    embedding_layer=transformer(input_ids, attention_mask=input_masks)[0]\n",
        "    #embedding_layer= tf.keras.layers.SpatialDropout1D(0.2)(embedding_layer)\n",
        "    \n",
        "    harmful=tf.keras.layers.Bidirectional(tf.keras.layers.GRU(256, return_sequences=True, dropout=0.3))(embedding_layer)\n",
        "    harmful=tf.keras.layers.Bidirectional(tf.keras.layers.GRU(128, return_sequences=True, dropout=0.3))(harmful)\n",
        "    harmful=tf.keras.layers.Bidirectional(tf.keras.layers.GRU(64, return_sequences=True, dropout=0.3))(harmful)\n",
        "    harmful = tf.keras.layers.Conv1D(64, kernel_size = 3, padding = \"valid\", kernel_initializer = \"glorot_uniform\")(harmful)\n",
        "    harmful = tf.keras.layers.Dropout(0.2)(harmful)\n",
        "    avg_pool_harmful = tf.keras.layers.GlobalAveragePooling1D()(harmful)\n",
        "    max_pool_harmful = tf.keras.layers.GlobalMaxPooling1D()(harmful)\n",
        "    harmful = tf.keras.layers.concatenate([avg_pool_harmful, max_pool_harmful])\n",
        "    harmful = tf.keras.layers.Dropout(0.1)(harmful)\n",
        "    output_harmful=tf.keras.layers.Dense(1, activation=\"sigmoid\",name=\"output_harmful\")(harmful)\n",
        "\n",
        "    model = tf.keras.Model(inputs=[input_ids, input_masks], outputs =output_harmful)\n",
        "    \n",
        "    return model"
      ],
      "id": "da19818d-f3ba-401d-a79a-4fdcad857dc9"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SsfndnmmFH0V",
        "outputId": "a889340a-bc88-43ae-bc80-d24cc8404b66"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertModel.\n",
            "\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at UBC-NLP/ARBERT.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/4\n",
            "29/29 [==============================] - 111s 2s/step - loss: 0.6480 - accuracy: 0.6602 - val_loss: 0.3847 - val_accuracy: 0.8300\n",
            "Epoch 2/4\n",
            "29/29 [==============================] - 10s 348ms/step - loss: 0.4700 - accuracy: 0.7729 - val_loss: 0.3355 - val_accuracy: 0.8511\n",
            "Epoch 3/4\n",
            "29/29 [==============================] - 10s 346ms/step - loss: 0.4063 - accuracy: 0.8173 - val_loss: 0.3034 - val_accuracy: 0.8602\n",
            "Epoch 4/4\n",
            "29/29 [==============================] - 10s 347ms/step - loss: 0.3732 - accuracy: 0.8331 - val_loss: 0.2912 - val_accuracy: 0.8692\n",
            "Epoch 1/12\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "29/29 [==============================] - 236s 4s/step - loss: 0.4018 - accuracy: 0.8260 - val_loss: 0.2593 - val_accuracy: 0.8903\n",
            "Epoch 2/12\n",
            "29/29 [==============================] - 17s 581ms/step - loss: 0.2432 - accuracy: 0.8997 - val_loss: 0.2683 - val_accuracy: 0.8893\n",
            "Epoch 3/12\n",
            "29/29 [==============================] - 17s 583ms/step - loss: 0.1560 - accuracy: 0.9507 - val_loss: 0.2547 - val_accuracy: 0.9044\n",
            "Epoch 4/12\n",
            "29/29 [==============================] - 17s 594ms/step - loss: 0.0922 - accuracy: 0.9772 - val_loss: 0.2685 - val_accuracy: 0.8944\n",
            "Epoch 5/12\n",
            "29/29 [==============================] - 17s 582ms/step - loss: 0.0568 - accuracy: 0.9881 - val_loss: 0.4125 - val_accuracy: 0.8702\n",
            "Epoch 6/12\n",
            "29/29 [==============================] - 17s 583ms/step - loss: 0.0403 - accuracy: 0.9902 - val_loss: 0.3251 - val_accuracy: 0.8984\n",
            "Epoch 7/12\n",
            "29/29 [==============================] - 17s 586ms/step - loss: 0.0264 - accuracy: 0.9930 - val_loss: 0.3328 - val_accuracy: 0.8964\n",
            "Epoch 8/12\n",
            "29/29 [==============================] - 17s 601ms/step - loss: 0.0226 - accuracy: 0.9957 - val_loss: 0.4231 - val_accuracy: 0.8853\n",
            "Epoch 9/12\n",
            "29/29 [==============================] - 17s 584ms/step - loss: 0.0153 - accuracy: 0.9973 - val_loss: 0.4028 - val_accuracy: 0.8924\n",
            "Epoch 10/12\n",
            "29/29 [==============================] - 17s 584ms/step - loss: 0.0156 - accuracy: 0.9957 - val_loss: 0.3845 - val_accuracy: 0.8934\n",
            "Epoch 11/12\n",
            "29/29 [==============================] - 17s 584ms/step - loss: 0.0106 - accuracy: 0.9967 - val_loss: 0.5028 - val_accuracy: 0.8803\n",
            "Epoch 12/12\n",
            "29/29 [==============================] - 17s 584ms/step - loss: 0.0251 - accuracy: 0.9902 - val_loss: 0.4094 - val_accuracy: 0.8893\n"
          ]
        }
      ],
      "source": [
        "def build_mono_model(compile=False,show_summary=False,pretrained_model=model_type):\n",
        "    with tpu_strategy.scope():\n",
        "      config =AutoConfig.from_pretrained(pretrained_model,dropout=0.2,seed=3,attention_dropout=0.2,output_hidden_states = True)\n",
        "      transformer= TFAutoModel.from_pretrained(pretrained_model,config=config)\n",
        "      model =create_mono_model(transformer)\n",
        "      if compile : \n",
        "          model.compile(loss={\"output_harmful\":\"binary_crossentropy\"},\n",
        "                      optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4), \n",
        "                      metrics={\"output_harmful\":\"accuracy\"}\n",
        "                     )\n",
        "      if show_summary:\n",
        "        model.summary()\n",
        "      return model\n",
        "\n",
        "model=build_mono_model()\n",
        "\n",
        "def train_model(model,train,valid,batch_size=64,epochs_frozen=4,epochs_unfrozen=12):\n",
        "      \n",
        "    # checkpoint_filepath = data_path\n",
        "\n",
        "    # model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    #     checkpoint_filepath, \n",
        "    #     monitor='val_loss', \n",
        "    #     save_weights_only=True, \n",
        "    #     save_best_only=True, \n",
        "    #     save_freq='epoch', \n",
        "    #     options=tf.train.CheckpointOptions(experimental_io_device='/job:localhost'))\n",
        "    \n",
        "    for layer in model.layers[:3]:\n",
        "        layer.trainable = False\n",
        "   \n",
        "    with tpu_strategy.scope():\n",
        "      model.compile(loss={\"output_harmful\":\"binary_crossentropy\"},\n",
        "                      optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4), \n",
        "                      metrics={\"output_harmful\":\"accuracy\"}\n",
        "                     )\n",
        "        \n",
        "    model.fit([train[\"input_ids\"], train[\"input_masks\"]],train[\"harmful_label\"],batch_size=batch_size,epochs=epochs_frozen,validation_data=([valid[\"input_ids\"],valid[\"input_masks\"]],valid[\"harmful_label\"]))#, callbacks=[model_checkpoint_callback])\n",
        "   \n",
        "    for layer in model.layers[:3]:\n",
        "        layer.trainable = True\n",
        "\n",
        "    with tpu_strategy.scope():\n",
        "      model.compile(loss={\"output_harmful\":\"binary_crossentropy\"}, \n",
        "                      optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5), \n",
        "                      metrics={\"output_harmful\":\"accuracy\"})\n",
        "    \n",
        "    model.fit([train[\"input_ids\"], train[\"input_masks\"]],train[\"harmful_label\"],batch_size=batch_size,epochs=epochs_unfrozen,validation_data=([valid[\"input_ids\"],valid[\"input_masks\"]],valid[\"harmful_label\"]))#, callbacks=[model_checkpoint_callback])\n",
        "\n",
        "train_model(model,train,valid)"
      ],
      "id": "SsfndnmmFH0V"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "csczZERXpEb7",
        "outputId": "2ccd03d1-b811-4f67-b8e2-f776d775f327"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'F1_macro': 0.6968085106382979, 'Accuracy': 0.8853118712273642, 'Precision_macro': 0.6931216931216931, 'Recall_macro': 0.7005347593582888}\n"
          ]
        }
      ],
      "source": [
        "def report_gen(predictions,labels,avg=\"binary\"):\n",
        "    report={\n",
        "    \"F1_macro\":f1_score(predictions,labels,average=avg),\n",
        "    \"Accuracy\":accuracy_score(predictions,labels),\n",
        "    \"Precision_macro\":precision_score(predictions,labels),\n",
        "    \"Recall_macro\":recall_score(predictions,labels)\n",
        "    }\n",
        "    return report\n",
        "\n",
        "def eval_task_harmful(predictions_harmful,labels_harmful):\n",
        "  predictions_harmful=[int(i>0.7) for i in predictions_harmful]\n",
        "  return report_gen(predictions_harmful,labels_harmful),predictions_harmful\n",
        "\n",
        "def eval_model(model,valid):\n",
        "    predictions_harmful=model.predict([valid[\"input_ids\"],valid[\"input_masks\"]])\n",
        "    report_harmful,predictions_harmful=eval_task_harmful(predictions_harmful,valid[\"harmful_label\"])\n",
        "    print(report_harmful)\n",
        "    return predictions_harmful\n",
        "\n",
        "predictions=eval_model(model,valid)"
      ],
      "id": "csczZERXpEb7"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "3nb0eZzhfA_q"
      },
      "outputs": [],
      "source": [
        "#128 64 64\n",
        "#{'F1_macro': 0.7364016736401674, 'Accuracy': 0.8732394366197183, 'Precision_macro': 0.9312169312169312, 'Recall_macro': 0.6089965397923875}\n",
        "#256 128 64\n",
        "#{'F1_macro': 0.7505720823798626, 'Accuracy': 0.8903420523138833, 'Precision_macro': 0.8677248677248677, 'Recall_macro': 0.6612903225806451}\n",
        "#256 128 64 32\n",
        "#{'F1_macro': 0.7443037974683544, 'Accuracy': 0.8983903420523138, 'Precision_macro': 0.7777777777777778, 'Recall_macro': 0.7135922330097088}\n",
        "#256 128 64 64\n",
        "#{'F1_macro': 0.7623762376237623, 'Accuracy': 0.903420523138833, 'Precision_macro': 0.8148148148148148, 'Recall_macro': 0.7162790697674418}\n",
        "#256 128 64 64\n",
        "#{'F1_macro': 0.7535545023696683, 'Accuracy': 0.8953722334004024, 'Precision_macro': 0.8412698412698413, 'Recall_macro': 0.6824034334763949}\n",
        "#256 128 64 (0.2) 64\n",
        "#{'F1_macro': 0.7611940298507462, 'Accuracy': 0.903420523138833, 'Precision_macro': 0.8095238095238095, 'Recall_macro': 0.7183098591549296}\n",
        "#12 epochs\n",
        "#{'F1_macro': 0.7436974789915967, 'Accuracy': 0.8772635814889336, 'Precision_macro': 0.9365079365079365, 'Recall_macro': 0.6167247386759582}\n",
        "\n",
        "#{'F1_macro': 0.7627906976744185, 'Accuracy': 0.89738430583501, 'Precision_macro': 0.8677248677248677, 'Recall_macro': 0.6804979253112033}\n",
        "# model.save_weights(model_path)"
      ],
      "id": "3nb0eZzhfA_q"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "rtj75RPE0Jk8"
      },
      "outputs": [],
      "source": [
        "#pd.DataFrame(predictions).to_csv(\"/content/predictions.csv\",index=False, header=None)"
      ],
      "id": "rtj75RPE0Jk8"
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Train-Mono-Models.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}